{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance_data = pd.read_csv('Data/insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Number of claims', 'Total payment'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of claims</th>\n",
       "      <th>Total payment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108</td>\n",
       "      <td>392.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>46.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>15.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>124</td>\n",
       "      <td>422.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>119.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>57</td>\n",
       "      <td>170.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23</td>\n",
       "      <td>56.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14</td>\n",
       "      <td>77.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>45</td>\n",
       "      <td>214.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>65.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of claims  Total payment\n",
       "0               108          392.5\n",
       "1                19           46.2\n",
       "2                13           15.7\n",
       "3               124          422.2\n",
       "4                40          119.4\n",
       "5                57          170.9\n",
       "6                23           56.9\n",
       "7                14           77.5\n",
       "8                45          214.0\n",
       "9                10           65.3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = insurance_data['Number of claims']\n",
    "y = insurance_data['Total payment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: (44,) (44,)\n",
      "Testing set size: (19,) (19,)\n"
     ]
    }
   ],
   "source": [
    "#train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0) # 70% training and 30% test\n",
    "print(\"Training set size:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing set size:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot data\n",
    "plt.scatter(x, y, marker='o')\n",
    "plt.ylabel('Total payment')\n",
    "plt.xlabel('Number of claims')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 9918.60266722\n",
      "Iteration 2, loss = 9747.55637854\n",
      "Iteration 3, loss = 9578.71437394\n",
      "Iteration 4, loss = 9412.02179293\n",
      "Iteration 5, loss = 9247.45407988\n",
      "Iteration 6, loss = 9084.99859675\n",
      "Iteration 7, loss = 8925.42957159\n",
      "Iteration 8, loss = 8768.43278312\n",
      "Iteration 9, loss = 8613.52777746\n",
      "Iteration 10, loss = 8461.69771325\n",
      "Iteration 11, loss = 8312.21276990\n",
      "Iteration 12, loss = 8164.48451340\n",
      "Iteration 13, loss = 8018.87608568\n",
      "Iteration 14, loss = 7874.58615698\n",
      "Iteration 15, loss = 7731.74650795\n",
      "Iteration 16, loss = 7590.29847739\n",
      "Iteration 17, loss = 7449.27972350\n",
      "Iteration 18, loss = 7308.58253021\n",
      "Iteration 19, loss = 7167.96979032\n",
      "Iteration 20, loss = 7027.25804746\n",
      "Iteration 21, loss = 6886.02297318\n",
      "Iteration 22, loss = 6744.09488361\n",
      "Iteration 23, loss = 6601.56083968\n",
      "Iteration 24, loss = 6457.94251034\n",
      "Iteration 25, loss = 6313.19154153\n",
      "Iteration 26, loss = 6168.09369645\n",
      "Iteration 27, loss = 6023.64243446\n",
      "Iteration 28, loss = 5879.13653465\n",
      "Iteration 29, loss = 5735.94808723\n",
      "Iteration 30, loss = 5593.01294242\n",
      "Iteration 31, loss = 5450.14460932\n",
      "Iteration 32, loss = 5306.39589434\n",
      "Iteration 33, loss = 5162.04846177\n",
      "Iteration 34, loss = 5017.77825786\n",
      "Iteration 35, loss = 4873.95446177\n",
      "Iteration 36, loss = 4730.31501561\n",
      "Iteration 37, loss = 4586.79477843\n",
      "Iteration 38, loss = 4443.22324161\n",
      "Iteration 39, loss = 4299.82610555\n",
      "Iteration 40, loss = 4156.77888360\n",
      "Iteration 41, loss = 4014.26408596\n",
      "Iteration 42, loss = 3871.99207123\n",
      "Iteration 43, loss = 3730.34332464\n",
      "Iteration 44, loss = 3589.57122024\n",
      "Iteration 45, loss = 3450.01099706\n",
      "Iteration 46, loss = 3311.80920470\n",
      "Iteration 47, loss = 3175.15099586\n",
      "Iteration 48, loss = 3040.23776782\n",
      "Iteration 49, loss = 2907.28754116\n",
      "Iteration 50, loss = 2776.51827696\n",
      "Iteration 51, loss = 2648.14974628\n",
      "Iteration 52, loss = 2522.40350007\n",
      "Iteration 53, loss = 2399.50043806\n",
      "Iteration 54, loss = 2279.65810418\n",
      "Iteration 55, loss = 2163.09065358\n",
      "Iteration 56, loss = 2050.00582798\n",
      "Iteration 57, loss = 1940.60438655\n",
      "Iteration 58, loss = 1835.09465806\n",
      "Iteration 59, loss = 1733.64548550\n",
      "Iteration 60, loss = 1636.41261481\n",
      "Iteration 61, loss = 1543.54652750\n",
      "Iteration 62, loss = 1455.18079609\n",
      "Iteration 63, loss = 1371.42953303\n",
      "Iteration 64, loss = 1292.38610941\n",
      "Iteration 65, loss = 1218.12213245\n",
      "Iteration 66, loss = 1148.68439363\n",
      "Iteration 67, loss = 1084.09425833\n",
      "Iteration 68, loss = 1024.34665372\n",
      "Iteration 69, loss = 969.40894060\n",
      "Iteration 70, loss = 919.21970839\n",
      "Iteration 71, loss = 873.68135021\n",
      "Iteration 72, loss = 832.67527919\n",
      "Iteration 73, loss = 796.05305973\n",
      "Iteration 74, loss = 763.64533481\n",
      "Iteration 75, loss = 735.26460640\n",
      "Iteration 76, loss = 710.69199127\n",
      "Iteration 77, loss = 689.70592064\n",
      "Iteration 78, loss = 672.06256729\n",
      "Iteration 79, loss = 657.49911147\n",
      "Iteration 80, loss = 645.71687619\n",
      "Iteration 81, loss = 636.47676524\n",
      "Iteration 82, loss = 629.46426280\n",
      "Iteration 83, loss = 624.42943745\n",
      "Iteration 84, loss = 621.09470044\n",
      "Iteration 85, loss = 619.15626644\n",
      "Iteration 86, loss = 618.34197653\n",
      "Iteration 87, loss = 618.44192352\n",
      "Iteration 88, loss = 619.21214421\n",
      "Iteration 89, loss = 620.43565638\n",
      "Iteration 90, loss = 621.92223638\n",
      "Iteration 91, loss = 623.50618775\n",
      "Iteration 92, loss = 625.05043999\n",
      "Iteration 93, loss = 626.45251123\n",
      "Iteration 94, loss = 627.63987512\n",
      "Iteration 95, loss = 628.56438565\n",
      "Iteration 96, loss = 629.20478337\n",
      "Iteration 97, loss = 629.55338748\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6085902462404278"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLP Regression model\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "X_train = x_train.values\n",
    "X_test = x_test.values\n",
    "\n",
    "\n",
    "modelReg = MLPRegressor(hidden_layer_sizes = 100,\n",
    "                        activation = 'relu',\n",
    "                        solver = 'adam',\n",
    "                        learning_rate_init = 0.003,\n",
    "                        max_iter=1000,\n",
    "                        random_state=0, \n",
    "                        verbose = 'True')\n",
    "\n",
    "modelReg.fit(X_train.reshape((-1,1)), y_train)\n",
    "modelReg.predict(X_test.reshape((-1, 1)))\n",
    "\n",
    "modelReg.score(X_test.reshape((-1, 1)), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "import pandas as pd\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "44/44 [==============================] - 1s 31ms/step - loss: 19726.8112\n",
      "Epoch 2/300\n",
      "44/44 [==============================] - 0s 664us/step - loss: 19725.0633\n",
      "Epoch 3/300\n",
      "44/44 [==============================] - 0s 682us/step - loss: 19723.7186\n",
      "Epoch 4/300\n",
      "44/44 [==============================] - 0s 717us/step - loss: 19722.5908\n",
      "Epoch 5/300\n",
      "44/44 [==============================] - 0s 762us/step - loss: 19721.7480\n",
      "Epoch 6/300\n",
      "44/44 [==============================] - 0s 637us/step - loss: 19721.0317\n",
      "Epoch 7/300\n",
      "44/44 [==============================] - 0s 936us/step - loss: 19720.4186\n",
      "Epoch 8/300\n",
      "44/44 [==============================] - 0s 766us/step - loss: 19719.9826\n",
      "Epoch 9/300\n",
      "44/44 [==============================] - 0s 858us/step - loss: 19719.5484\n",
      "Epoch 10/300\n",
      "44/44 [==============================] - 0s 725us/step - loss: 19719.1796\n",
      "Epoch 11/300\n",
      "44/44 [==============================] - 0s 644us/step - loss: 19718.9411\n",
      "Epoch 12/300\n",
      "44/44 [==============================] - 0s 710us/step - loss: 19718.6567\n",
      "Epoch 13/300\n",
      "44/44 [==============================] - 0s 649us/step - loss: 19718.4575\n",
      "Epoch 14/300\n",
      "44/44 [==============================] - ETA: 0s - loss: 13153.107 - 0s 609us/step - loss: 19718.2765\n",
      "Epoch 15/300\n",
      "44/44 [==============================] - 0s 640us/step - loss: 19718.1072\n",
      "Epoch 16/300\n",
      "44/44 [==============================] - 0s 577us/step - loss: 19717.9693\n",
      "Epoch 17/300\n",
      "44/44 [==============================] - 0s 528us/step - loss: 19717.8414\n",
      "Epoch 18/300\n",
      "44/44 [==============================] - 0s 495us/step - loss: 19717.7112\n",
      "Epoch 19/300\n",
      "44/44 [==============================] - 0s 579us/step - loss: 19717.6089\n",
      "Epoch 20/300\n",
      "44/44 [==============================] - 0s 613us/step - loss: 19717.5156\n",
      "Epoch 21/300\n",
      "44/44 [==============================] - 0s 577us/step - loss: 19717.4287\n",
      "Epoch 22/300\n",
      "44/44 [==============================] - 0s 858us/step - loss: 19717.3399\n",
      "Epoch 23/300\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 19717.2576\n",
      "Epoch 24/300\n",
      "44/44 [==============================] - 0s 606us/step - loss: 19717.1939\n",
      "Epoch 25/300\n",
      "44/44 [==============================] - 0s 845us/step - loss: 19717.1329\n",
      "Epoch 26/300\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 19717.0714\n",
      "Epoch 27/300\n",
      "44/44 [==============================] - 0s 707us/step - loss: 19717.0242\n",
      "Epoch 28/300\n",
      "44/44 [==============================] - 0s 721us/step - loss: 19716.9753\n",
      "Epoch 29/300\n",
      "44/44 [==============================] - 0s 829us/step - loss: 19716.9339\n",
      "Epoch 30/300\n",
      "44/44 [==============================] - 0s 911us/step - loss: 19716.8928\n",
      "Epoch 31/300\n",
      "44/44 [==============================] - 0s 846us/step - loss: 19716.8572\n",
      "Epoch 32/300\n",
      "44/44 [==============================] - 0s 836us/step - loss: 19716.8234\n",
      "Epoch 33/300\n",
      "44/44 [==============================] - 0s 616us/step - loss: 19716.7903\n",
      "Epoch 34/300\n",
      "44/44 [==============================] - 0s 720us/step - loss: 19716.7639\n",
      "Epoch 35/300\n",
      "44/44 [==============================] - 0s 494us/step - loss: 19716.7345\n",
      "Epoch 36/300\n",
      "44/44 [==============================] - 0s 929us/step - loss: 19716.7161\n",
      "Epoch 37/300\n",
      "44/44 [==============================] - 0s 604us/step - loss: 19716.6852\n",
      "Epoch 38/300\n",
      "44/44 [==============================] - 0s 683us/step - loss: 19716.6631\n",
      "Epoch 39/300\n",
      "44/44 [==============================] - 0s 684us/step - loss: 19716.6430\n",
      "Epoch 40/300\n",
      "44/44 [==============================] - 0s 541us/step - loss: 19716.6232\n",
      "Epoch 41/300\n",
      "44/44 [==============================] - 0s 514us/step - loss: 19716.6048\n",
      "Epoch 42/300\n",
      "44/44 [==============================] - 0s 597us/step - loss: 19716.5855\n",
      "Epoch 43/300\n",
      "44/44 [==============================] - 0s 655us/step - loss: 19716.5658\n",
      "Epoch 44/300\n",
      "44/44 [==============================] - 0s 720us/step - loss: 19716.5510\n",
      "Epoch 45/300\n",
      "44/44 [==============================] - 0s 766us/step - loss: 19716.5363\n",
      "Epoch 46/300\n",
      "44/44 [==============================] - 0s 698us/step - loss: 19716.5208\n",
      "Epoch 47/300\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 19716.5061\n",
      "Epoch 48/300\n",
      "44/44 [==============================] - 0s 656us/step - loss: 19716.4936\n",
      "Epoch 49/300\n",
      "44/44 [==============================] - 0s 534us/step - loss: 19716.4814\n",
      "Epoch 50/300\n",
      "44/44 [==============================] - 0s 677us/step - loss: 19716.4680\n",
      "Epoch 51/300\n",
      "44/44 [==============================] - 0s 655us/step - loss: 19716.4571\n",
      "Epoch 52/300\n",
      "44/44 [==============================] - 0s 763us/step - loss: 19716.4471\n",
      "Epoch 53/300\n",
      "44/44 [==============================] - 0s 667us/step - loss: 19716.4335\n",
      "Epoch 54/300\n",
      "44/44 [==============================] - 0s 851us/step - loss: 19716.4242\n",
      "Epoch 55/300\n",
      "44/44 [==============================] - 0s 488us/step - loss: 19716.4160\n",
      "Epoch 56/300\n",
      "44/44 [==============================] - 0s 793us/step - loss: 19716.4083\n",
      "Epoch 57/300\n",
      "44/44 [==============================] - 0s 485us/step - loss: 19716.3995\n",
      "Epoch 58/300\n",
      "44/44 [==============================] - 0s 648us/step - loss: 19716.3923\n",
      "Epoch 59/300\n",
      "44/44 [==============================] - 0s 670us/step - loss: 19716.3846\n",
      "Epoch 60/300\n",
      "44/44 [==============================] - 0s 503us/step - loss: 19716.3772\n",
      "Epoch 61/300\n",
      "44/44 [==============================] - 0s 491us/step - loss: 19716.3707\n",
      "Epoch 62/300\n",
      "44/44 [==============================] - 0s 370us/step - loss: 19716.3652\n",
      "Epoch 63/300\n",
      "44/44 [==============================] - 0s 400us/step - loss: 19716.3576\n",
      "Epoch 64/300\n",
      "44/44 [==============================] - 0s 515us/step - loss: 19716.3509\n",
      "Epoch 65/300\n",
      "44/44 [==============================] - 0s 335us/step - loss: 19716.3453\n",
      "Epoch 66/300\n",
      "44/44 [==============================] - 0s 503us/step - loss: 19716.3386\n",
      "Epoch 67/300\n",
      "44/44 [==============================] - 0s 595us/step - loss: 19716.3325\n",
      "Epoch 68/300\n",
      "44/44 [==============================] - 0s 626us/step - loss: 19716.3278\n",
      "Epoch 69/300\n",
      "44/44 [==============================] - 0s 782us/step - loss: 19716.3216\n",
      "Epoch 70/300\n",
      "44/44 [==============================] - 0s 624us/step - loss: 19716.3158\n",
      "Epoch 71/300\n",
      "44/44 [==============================] - 0s 499us/step - loss: 19716.3112\n",
      "Epoch 72/300\n",
      "44/44 [==============================] - 0s 568us/step - loss: 19716.3070\n",
      "Epoch 73/300\n",
      "44/44 [==============================] - 0s 658us/step - loss: 19716.3018\n",
      "Epoch 74/300\n",
      "44/44 [==============================] - 0s 561us/step - loss: 19716.2971\n",
      "Epoch 75/300\n",
      "44/44 [==============================] - 0s 501us/step - loss: 19716.2932\n",
      "Epoch 76/300\n",
      "44/44 [==============================] - 0s 555us/step - loss: 19716.2886\n",
      "Epoch 77/300\n",
      "44/44 [==============================] - 0s 527us/step - loss: 19716.2848\n",
      "Epoch 78/300\n",
      "44/44 [==============================] - 0s 668us/step - loss: 19716.2809\n",
      "Epoch 79/300\n",
      "44/44 [==============================] - 0s 480us/step - loss: 19716.2773\n",
      "Epoch 80/300\n",
      "44/44 [==============================] - 0s 975us/step - loss: 19716.2732\n",
      "Epoch 81/300\n",
      "44/44 [==============================] - 0s 597us/step - loss: 19716.2692\n",
      "Epoch 82/300\n",
      "44/44 [==============================] - 0s 680us/step - loss: 19716.2665\n",
      "Epoch 83/300\n",
      "44/44 [==============================] - 0s 774us/step - loss: 19716.2624\n",
      "Epoch 84/300\n",
      "44/44 [==============================] - 0s 706us/step - loss: 19716.2615\n",
      "Epoch 85/300\n",
      "44/44 [==============================] - 0s 805us/step - loss: 19716.2577\n",
      "Epoch 86/300\n",
      "44/44 [==============================] - 0s 865us/step - loss: 19716.2544\n",
      "Epoch 87/300\n",
      "44/44 [==============================] - 0s 590us/step - loss: 19716.2512\n",
      "Epoch 88/300\n",
      "44/44 [==============================] - 0s 640us/step - loss: 19716.2490\n",
      "Epoch 89/300\n",
      "44/44 [==============================] - 0s 592us/step - loss: 19716.2458\n",
      "Epoch 90/300\n",
      "44/44 [==============================] - 0s 600us/step - loss: 19716.2436\n",
      "Epoch 91/300\n",
      "44/44 [==============================] - 0s 598us/step - loss: 19716.2397\n",
      "Epoch 92/300\n",
      "44/44 [==============================] - 0s 578us/step - loss: 19716.2384\n",
      "Epoch 93/300\n",
      "44/44 [==============================] - 0s 626us/step - loss: 19716.2365\n",
      "Epoch 94/300\n",
      "44/44 [==============================] - 0s 704us/step - loss: 19716.2331\n",
      "Epoch 95/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 806us/step - loss: 19716.2309\n",
      "Epoch 96/300\n",
      "44/44 [==============================] - 0s 646us/step - loss: 19716.2295\n",
      "Epoch 97/300\n",
      "44/44 [==============================] - 0s 727us/step - loss: 19716.2266\n",
      "Epoch 98/300\n",
      "44/44 [==============================] - 0s 701us/step - loss: 19716.2243\n",
      "Epoch 99/300\n",
      "44/44 [==============================] - 0s 706us/step - loss: 19716.2226\n",
      "Epoch 100/300\n",
      "44/44 [==============================] - 0s 666us/step - loss: 19716.2197\n",
      "Epoch 101/300\n",
      "44/44 [==============================] - 0s 529us/step - loss: 19716.2174\n",
      "Epoch 102/300\n",
      "44/44 [==============================] - 0s 644us/step - loss: 19716.2161\n",
      "Epoch 103/300\n",
      "44/44 [==============================] - 0s 777us/step - loss: 19716.2136\n",
      "Epoch 104/300\n",
      "44/44 [==============================] - 0s 635us/step - loss: 19716.2110\n",
      "Epoch 105/300\n",
      "44/44 [==============================] - 0s 752us/step - loss: 19716.2089\n",
      "Epoch 106/300\n",
      "44/44 [==============================] - 0s 496us/step - loss: 19716.2074\n",
      "Epoch 107/300\n",
      "44/44 [==============================] - 0s 675us/step - loss: 19716.2053\n",
      "Epoch 108/300\n",
      "44/44 [==============================] - 0s 646us/step - loss: 19716.2037\n",
      "Epoch 109/300\n",
      "44/44 [==============================] - 0s 659us/step - loss: 19716.2010\n",
      "Epoch 110/300\n",
      "44/44 [==============================] - 0s 615us/step - loss: 19716.2006\n",
      "Epoch 111/300\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 19716.1986\n",
      "Epoch 112/300\n",
      "44/44 [==============================] - 0s 792us/step - loss: 19716.1965\n",
      "Epoch 113/300\n",
      "44/44 [==============================] - 0s 910us/step - loss: 19716.1958\n",
      "Epoch 114/300\n",
      "44/44 [==============================] - 0s 609us/step - loss: 19716.1934\n",
      "Epoch 115/300\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 19716.1928\n",
      "Epoch 116/300\n",
      "44/44 [==============================] - 0s 687us/step - loss: 19716.1909\n",
      "Epoch 117/300\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 19716.1886\n",
      "Epoch 118/300\n",
      "44/44 [==============================] - 0s 639us/step - loss: 19716.1877\n",
      "Epoch 119/300\n",
      "44/44 [==============================] - 0s 774us/step - loss: 19716.1867\n",
      "Epoch 120/300\n",
      "44/44 [==============================] - 0s 521us/step - loss: 19716.1846\n",
      "Epoch 121/300\n",
      "44/44 [==============================] - 0s 524us/step - loss: 19716.1836\n",
      "Epoch 122/300\n",
      "44/44 [==============================] - 0s 643us/step - loss: 19716.1824\n",
      "Epoch 123/300\n",
      "44/44 [==============================] - 0s 557us/step - loss: 19716.1811\n",
      "Epoch 124/300\n",
      "44/44 [==============================] - 0s 498us/step - loss: 19716.1793\n",
      "Epoch 125/300\n",
      "44/44 [==============================] - 0s 455us/step - loss: 19716.1783\n",
      "Epoch 126/300\n",
      "44/44 [==============================] - 0s 664us/step - loss: 19716.1768\n",
      "Epoch 127/300\n",
      "44/44 [==============================] - 0s 574us/step - loss: 19716.1767\n",
      "Epoch 128/300\n",
      "44/44 [==============================] - 0s 545us/step - loss: 19716.1747\n",
      "Epoch 129/300\n",
      "44/44 [==============================] - 0s 384us/step - loss: 19716.1735\n",
      "Epoch 130/300\n",
      "44/44 [==============================] - 0s 438us/step - loss: 19716.1725\n",
      "Epoch 131/300\n",
      "44/44 [==============================] - 0s 541us/step - loss: 19716.1715\n",
      "Epoch 132/300\n",
      "44/44 [==============================] - 0s 471us/step - loss: 19716.1708\n",
      "Epoch 133/300\n",
      "44/44 [==============================] - 0s 805us/step - loss: 19716.1682\n",
      "Epoch 134/300\n",
      "44/44 [==============================] - 0s 537us/step - loss: 19716.1681\n",
      "Epoch 135/300\n",
      "44/44 [==============================] - 0s 540us/step - loss: 19716.1668\n",
      "Epoch 136/300\n",
      "44/44 [==============================] - 0s 669us/step - loss: 19716.1651\n",
      "Epoch 137/300\n",
      "44/44 [==============================] - 0s 565us/step - loss: 19716.1646\n",
      "Epoch 138/300\n",
      "44/44 [==============================] - 0s 603us/step - loss: 19716.1634\n",
      "Epoch 139/300\n",
      "44/44 [==============================] - 0s 482us/step - loss: 19716.1633\n",
      "Epoch 140/300\n",
      "44/44 [==============================] - 0s 565us/step - loss: 19716.1614\n",
      "Epoch 141/300\n",
      "44/44 [==============================] - 0s 718us/step - loss: 19716.1606\n",
      "Epoch 142/300\n",
      "44/44 [==============================] - 0s 447us/step - loss: 19716.1598\n",
      "Epoch 143/300\n",
      "44/44 [==============================] - 0s 540us/step - loss: 19716.1582\n",
      "Epoch 144/300\n",
      "44/44 [==============================] - 0s 642us/step - loss: 19716.1573\n",
      "Epoch 145/300\n",
      "44/44 [==============================] - 0s 343us/step - loss: 19716.1571\n",
      "Epoch 146/300\n",
      "44/44 [==============================] - 0s 454us/step - loss: 19716.1565\n",
      "Epoch 147/300\n",
      "44/44 [==============================] - 0s 398us/step - loss: 19716.1548\n",
      "Epoch 148/300\n",
      "44/44 [==============================] - 0s 708us/step - loss: 19716.1549\n",
      "Epoch 149/300\n",
      "44/44 [==============================] - 0s 338us/step - loss: 19716.1531\n",
      "Epoch 150/300\n",
      "44/44 [==============================] - 0s 315us/step - loss: 19716.1529\n",
      "Epoch 151/300\n",
      "44/44 [==============================] - 0s 343us/step - loss: 19716.1521\n",
      "Epoch 152/300\n",
      "44/44 [==============================] - 0s 332us/step - loss: 19716.1514\n",
      "Epoch 153/300\n",
      "44/44 [==============================] - 0s 333us/step - loss: 19716.1505\n",
      "Epoch 154/300\n",
      "44/44 [==============================] - 0s 315us/step - loss: 19716.1504\n",
      "Epoch 155/300\n",
      "44/44 [==============================] - 0s 316us/step - loss: 19716.1488\n",
      "Epoch 156/300\n",
      "44/44 [==============================] - 0s 312us/step - loss: 19716.1483\n",
      "Epoch 157/300\n",
      "44/44 [==============================] - 0s 355us/step - loss: 19716.1477\n",
      "Epoch 158/300\n",
      "44/44 [==============================] - 0s 314us/step - loss: 19716.1475\n",
      "Epoch 159/300\n",
      "44/44 [==============================] - 0s 343us/step - loss: 19716.1471\n",
      "Epoch 160/300\n",
      "44/44 [==============================] - 0s 361us/step - loss: 19716.1452\n",
      "Epoch 161/300\n",
      "44/44 [==============================] - 0s 489us/step - loss: 19716.1439\n",
      "Epoch 162/300\n",
      "44/44 [==============================] - 0s 332us/step - loss: 19716.1441\n",
      "Epoch 163/300\n",
      "44/44 [==============================] - 0s 338us/step - loss: 19716.1444\n",
      "Epoch 164/300\n",
      "44/44 [==============================] - 0s 350us/step - loss: 19716.1430\n",
      "Epoch 165/300\n",
      "44/44 [==============================] - 0s 318us/step - loss: 19716.1420\n",
      "Epoch 166/300\n",
      "44/44 [==============================] - 0s 348us/step - loss: 19716.1421\n",
      "Epoch 167/300\n",
      "44/44 [==============================] - 0s 316us/step - loss: 19716.1419\n",
      "Epoch 168/300\n",
      "44/44 [==============================] - 0s 328us/step - loss: 19716.1408\n",
      "Epoch 169/300\n",
      "44/44 [==============================] - 0s 350us/step - loss: 19716.1397\n",
      "Epoch 170/300\n",
      "44/44 [==============================] - 0s 321us/step - loss: 19716.1390\n",
      "Epoch 171/300\n",
      "44/44 [==============================] - 0s 308us/step - loss: 19716.1381\n",
      "Epoch 172/300\n",
      "44/44 [==============================] - 0s 317us/step - loss: 19716.1376\n",
      "Epoch 173/300\n",
      "44/44 [==============================] - 0s 320us/step - loss: 19716.1373\n",
      "Epoch 174/300\n",
      "44/44 [==============================] - 0s 352us/step - loss: 19716.1361\n",
      "Epoch 175/300\n",
      "44/44 [==============================] - 0s 400us/step - loss: 19716.1370\n",
      "Epoch 176/300\n",
      "44/44 [==============================] - 0s 323us/step - loss: 19716.1350\n",
      "Epoch 177/300\n",
      "44/44 [==============================] - 0s 323us/step - loss: 19716.1353\n",
      "Epoch 178/300\n",
      "44/44 [==============================] - 0s 461us/step - loss: 19716.1340\n",
      "Epoch 179/300\n",
      "44/44 [==============================] - 0s 312us/step - loss: 19716.1350\n",
      "Epoch 180/300\n",
      "44/44 [==============================] - 0s 312us/step - loss: 19716.1346\n",
      "Epoch 181/300\n",
      "44/44 [==============================] - 0s 313us/step - loss: 19716.1337\n",
      "Epoch 182/300\n",
      "44/44 [==============================] - 0s 320us/step - loss: 19716.1323\n",
      "Epoch 183/300\n",
      "44/44 [==============================] - 0s 318us/step - loss: 19716.1329\n",
      "Epoch 184/300\n",
      "44/44 [==============================] - 0s 312us/step - loss: 19716.1319\n",
      "Epoch 185/300\n",
      "44/44 [==============================] - 0s 311us/step - loss: 19716.1307\n",
      "Epoch 186/300\n",
      "44/44 [==============================] - 0s 312us/step - loss: 19716.1302\n",
      "Epoch 187/300\n",
      "44/44 [==============================] - 0s 312us/step - loss: 19716.1289\n",
      "Epoch 188/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 307us/step - loss: 19716.1289\n",
      "Epoch 189/300\n",
      "44/44 [==============================] - 0s 332us/step - loss: 19716.1294\n",
      "Epoch 190/300\n",
      "44/44 [==============================] - 0s 354us/step - loss: 19716.1294\n",
      "Epoch 191/300\n",
      "44/44 [==============================] - 0s 344us/step - loss: 19716.1282\n",
      "Epoch 192/300\n",
      "44/44 [==============================] - 0s 325us/step - loss: 19716.1274\n",
      "Epoch 193/300\n",
      "44/44 [==============================] - 0s 317us/step - loss: 19716.1280\n",
      "Epoch 194/300\n",
      "44/44 [==============================] - 0s 334us/step - loss: 19716.1275\n",
      "Epoch 195/300\n",
      "44/44 [==============================] - 0s 316us/step - loss: 19716.1267\n",
      "Epoch 196/300\n",
      "44/44 [==============================] - 0s 460us/step - loss: 19716.1265\n",
      "Epoch 197/300\n",
      "44/44 [==============================] - 0s 330us/step - loss: 19716.1262\n",
      "Epoch 198/300\n",
      "44/44 [==============================] - 0s 324us/step - loss: 19716.1245\n",
      "Epoch 199/300\n",
      "44/44 [==============================] - 0s 323us/step - loss: 19716.1244\n",
      "Epoch 200/300\n",
      "44/44 [==============================] - 0s 331us/step - loss: 19716.1237\n",
      "Epoch 201/300\n",
      "44/44 [==============================] - 0s 317us/step - loss: 19716.1245\n",
      "Epoch 202/300\n",
      "44/44 [==============================] - 0s 326us/step - loss: 19716.1238\n",
      "Epoch 203/300\n",
      "44/44 [==============================] - 0s 312us/step - loss: 19716.1231\n",
      "Epoch 204/300\n",
      "44/44 [==============================] - 0s 335us/step - loss: 19716.1220\n",
      "Epoch 205/300\n",
      "44/44 [==============================] - 0s 328us/step - loss: 19716.1229\n",
      "Epoch 206/300\n",
      "44/44 [==============================] - 0s 494us/step - loss: 19716.1218\n",
      "Epoch 207/300\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 19716.1224\n",
      "Epoch 208/300\n",
      "44/44 [==============================] - 0s 618us/step - loss: 19716.1217\n",
      "Epoch 209/300\n",
      "44/44 [==============================] - 0s 742us/step - loss: 19716.1206\n",
      "Epoch 210/300\n",
      "44/44 [==============================] - 0s 659us/step - loss: 19716.1203\n",
      "Epoch 211/300\n",
      "44/44 [==============================] - 0s 874us/step - loss: 19716.1200\n",
      "Epoch 212/300\n",
      "44/44 [==============================] - 0s 693us/step - loss: 19716.1193\n",
      "Epoch 213/300\n",
      "44/44 [==============================] - 0s 736us/step - loss: 19716.1195\n",
      "Epoch 214/300\n",
      "44/44 [==============================] - 0s 597us/step - loss: 19716.1193\n",
      "Epoch 215/300\n",
      "44/44 [==============================] - 0s 838us/step - loss: 19716.1182\n",
      "Epoch 216/300\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 19716.1181\n",
      "Epoch 217/300\n",
      "44/44 [==============================] - 0s 645us/step - loss: 19716.1185\n",
      "Epoch 218/300\n",
      "44/44 [==============================] - 0s 581us/step - loss: 19716.1178\n",
      "Epoch 219/300\n",
      "44/44 [==============================] - 0s 586us/step - loss: 19716.1173\n",
      "Epoch 220/300\n",
      "44/44 [==============================] - 0s 566us/step - loss: 19716.1176\n",
      "Epoch 221/300\n",
      "44/44 [==============================] - 0s 691us/step - loss: 19716.1172\n",
      "Epoch 222/300\n",
      "44/44 [==============================] - 0s 491us/step - loss: 19716.1159\n",
      "Epoch 223/300\n",
      "44/44 [==============================] - 0s 755us/step - loss: 19716.1161\n",
      "Epoch 224/300\n",
      "44/44 [==============================] - 0s 828us/step - loss: 19716.1164\n",
      "Epoch 225/300\n",
      "44/44 [==============================] - 0s 879us/step - loss: 19716.1152\n",
      "Epoch 226/300\n",
      "44/44 [==============================] - 0s 811us/step - loss: 19716.1153\n",
      "Epoch 227/300\n",
      "44/44 [==============================] - 0s 597us/step - loss: 19716.1138\n",
      "Epoch 228/300\n",
      "44/44 [==============================] - 0s 2ms/step - loss: 19716.1139\n",
      "Epoch 229/300\n",
      "44/44 [==============================] - 0s 725us/step - loss: 19716.1142\n",
      "Epoch 230/300\n",
      "44/44 [==============================] - 0s 533us/step - loss: 19716.1137\n",
      "Epoch 231/300\n",
      "44/44 [==============================] - 0s 721us/step - loss: 19716.1136\n",
      "Epoch 232/300\n",
      "44/44 [==============================] - 0s 651us/step - loss: 19716.1143\n",
      "Epoch 233/300\n",
      "44/44 [==============================] - 0s 696us/step - loss: 19716.1136\n",
      "Epoch 234/300\n",
      "44/44 [==============================] - 0s 673us/step - loss: 19716.1131\n",
      "Epoch 235/300\n",
      "44/44 [==============================] - 0s 677us/step - loss: 19716.1123\n",
      "Epoch 236/300\n",
      "44/44 [==============================] - 0s 534us/step - loss: 19716.1123\n",
      "Epoch 237/300\n",
      "44/44 [==============================] - 0s 434us/step - loss: 19716.1120\n",
      "Epoch 238/300\n",
      "44/44 [==============================] - 0s 571us/step - loss: 19716.1123\n",
      "Epoch 239/300\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 19716.1116\n",
      "Epoch 240/300\n",
      "44/44 [==============================] - 0s 551us/step - loss: 19716.1110\n",
      "Epoch 241/300\n",
      "44/44 [==============================] - 0s 672us/step - loss: 19716.1117\n",
      "Epoch 242/300\n",
      "44/44 [==============================] - 0s 724us/step - loss: 19716.1116\n",
      "Epoch 243/300\n",
      "44/44 [==============================] - 0s 911us/step - loss: 19716.1123\n",
      "Epoch 244/300\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 19716.1109\n",
      "Epoch 245/300\n",
      "44/44 [==============================] - 0s 677us/step - loss: 19716.1108\n",
      "Epoch 246/300\n",
      "44/44 [==============================] - 0s 717us/step - loss: 19716.1097\n",
      "Epoch 247/300\n",
      "44/44 [==============================] - 0s 530us/step - loss: 19716.1088\n",
      "Epoch 248/300\n",
      "44/44 [==============================] - 0s 695us/step - loss: 19716.1094\n",
      "Epoch 249/300\n",
      "44/44 [==============================] - 0s 737us/step - loss: 19716.1087\n",
      "Epoch 250/300\n",
      "44/44 [==============================] - 0s 443us/step - loss: 19716.1094\n",
      "Epoch 251/300\n",
      "44/44 [==============================] - 0s 612us/step - loss: 19716.1083\n",
      "Epoch 252/300\n",
      "44/44 [==============================] - 0s 576us/step - loss: 19716.1091\n",
      "Epoch 253/300\n",
      "44/44 [==============================] - 0s 509us/step - loss: 19716.1084\n",
      "Epoch 254/300\n",
      "44/44 [==============================] - 0s 622us/step - loss: 19716.1073\n",
      "Epoch 255/300\n",
      "44/44 [==============================] - 0s 531us/step - loss: 19716.1084\n",
      "Epoch 256/300\n",
      "44/44 [==============================] - 0s 657us/step - loss: 19716.1078\n",
      "Epoch 257/300\n",
      "44/44 [==============================] - 0s 531us/step - loss: 19716.1075\n",
      "Epoch 258/300\n",
      "44/44 [==============================] - 0s 491us/step - loss: 19716.1073\n",
      "Epoch 259/300\n",
      "44/44 [==============================] - 0s 974us/step - loss: 19716.1068\n",
      "Epoch 260/300\n",
      "44/44 [==============================] - 0s 612us/step - loss: 19716.1063\n",
      "Epoch 261/300\n",
      "44/44 [==============================] - 0s 582us/step - loss: 19716.1064\n",
      "Epoch 262/300\n",
      "44/44 [==============================] - 0s 566us/step - loss: 19716.1060\n",
      "Epoch 263/300\n",
      "44/44 [==============================] - 0s 684us/step - loss: 19716.1062\n",
      "Epoch 264/300\n",
      "44/44 [==============================] - 0s 606us/step - loss: 19716.1064\n",
      "Epoch 265/300\n",
      "44/44 [==============================] - 0s 535us/step - loss: 19716.1054\n",
      "Epoch 266/300\n",
      "44/44 [==============================] - 0s 709us/step - loss: 19716.1061\n",
      "Epoch 267/300\n",
      "44/44 [==============================] - 0s 472us/step - loss: 19716.1059\n",
      "Epoch 268/300\n",
      "44/44 [==============================] - 0s 743us/step - loss: 19716.1054\n",
      "Epoch 269/300\n",
      "44/44 [==============================] - 0s 751us/step - loss: 19716.1043\n",
      "Epoch 270/300\n",
      "44/44 [==============================] - 0s 470us/step - loss: 19716.1040\n",
      "Epoch 271/300\n",
      "44/44 [==============================] - 0s 720us/step - loss: 19716.1047\n",
      "Epoch 272/300\n",
      "44/44 [==============================] - 0s 753us/step - loss: 19716.1038\n",
      "Epoch 273/300\n",
      "44/44 [==============================] - 0s 466us/step - loss: 19716.1050\n",
      "Epoch 274/300\n",
      "44/44 [==============================] - 0s 496us/step - loss: 19716.1037\n",
      "Epoch 275/300\n",
      "44/44 [==============================] - 0s 504us/step - loss: 19716.1033\n",
      "Epoch 276/300\n",
      "44/44 [==============================] - 0s 698us/step - loss: 19716.1042\n",
      "Epoch 277/300\n",
      "44/44 [==============================] - 0s 504us/step - loss: 19716.1039\n",
      "Epoch 278/300\n",
      "44/44 [==============================] - 0s 538us/step - loss: 19716.1033\n",
      "Epoch 279/300\n",
      "44/44 [==============================] - 0s 528us/step - loss: 19716.1031\n",
      "Epoch 280/300\n",
      "44/44 [==============================] - 0s 629us/step - loss: 19716.1024\n",
      "Epoch 281/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 544us/step - loss: 19716.1034\n",
      "Epoch 282/300\n",
      "44/44 [==============================] - 0s 663us/step - loss: 19716.1020\n",
      "Epoch 283/300\n",
      "44/44 [==============================] - 0s 685us/step - loss: 19716.1025\n",
      "Epoch 284/300\n",
      "44/44 [==============================] - 0s 406us/step - loss: 19716.1025\n",
      "Epoch 285/300\n",
      "44/44 [==============================] - 0s 546us/step - loss: 19716.1018\n",
      "Epoch 286/300\n",
      "44/44 [==============================] - 0s 470us/step - loss: 19716.1021\n",
      "Epoch 287/300\n",
      "44/44 [==============================] - 0s 521us/step - loss: 19716.1020\n",
      "Epoch 288/300\n",
      "44/44 [==============================] - 0s 439us/step - loss: 19716.1022\n",
      "Epoch 289/300\n",
      "44/44 [==============================] - 0s 496us/step - loss: 19716.1017\n",
      "Epoch 290/300\n",
      "44/44 [==============================] - 0s 709us/step - loss: 19716.1018\n",
      "Epoch 291/300\n",
      "44/44 [==============================] - 0s 608us/step - loss: 19716.1017\n",
      "Epoch 292/300\n",
      "44/44 [==============================] - 0s 602us/step - loss: 19716.1005\n",
      "Epoch 293/300\n",
      "44/44 [==============================] - 0s 506us/step - loss: 19716.1008\n",
      "Epoch 294/300\n",
      "44/44 [==============================] - 0s 420us/step - loss: 19716.0995\n",
      "Epoch 295/300\n",
      "44/44 [==============================] - 0s 475us/step - loss: 19716.1005\n",
      "Epoch 296/300\n",
      "44/44 [==============================] - 0s 549us/step - loss: 19716.1003\n",
      "Epoch 297/300\n",
      "44/44 [==============================] - 0s 597us/step - loss: 19716.1003\n",
      "Epoch 298/300\n",
      "44/44 [==============================] - 0s 516us/step - loss: 19716.1001\n",
      "Epoch 299/300\n",
      "44/44 [==============================] - 0s 610us/step - loss: 19716.0996\n",
      "Epoch 300/300\n",
      "44/44 [==============================] - 0s 658us/step - loss: 19716.1006\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fa29fa4e1d0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(8, activation='relu', input_shape=(1,)))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')\n",
    "                   \n",
    "model.fit(x_train, y_train,epochs=300, batch_size=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'estimator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-ff8e49ddeffd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mkfold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results: %.2f (%.2f) MSE\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'estimator' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "kfold = KFold(n_splits=10)\n",
    "results = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Results: %.2f (%.2f) MSE\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
