{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D_6vwRCzJFs_"
   },
   "source": [
    "# **Decision Trees**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5Ri-PSUI-JF"
   },
   "outputs": [],
   "source": [
    "# Import modules and libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split # Import train_test_split function\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset\n",
    "\n",
    "The Iris is a classical machine learning dataset (https://en.wikipedia.org/wiki/Iris_flower_data_set), composed of Iris plants. \n",
    "The iris samples in question fall into three species: Iris setosa, Iris versicolor, and Iris virginica. The objective is to classify plants based on the lengths and widths of their petals and sepals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the dataset using the sklearn library\n",
    "from sklearn import datasets\n",
    "data_url = 'https://github.com/abdelrahman-ayad/MiCM-introML-W21/raw/main/notebooks/Data/IrisDataset.csv'\n",
    "dataset = pd.read_csv(data_url)\n",
    "\n",
    "# Display the first ten rows of dataset\n",
    "dataset.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign features and targets (labels) from the dataset\n",
    "y = dataset['target']\n",
    "x = dataset[dataset.columns.drop('target')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(num_instances, num_features), num_classes = x.shape, np.max(y)+1\n",
    "print (\"number of instances (Dataset size):\", num_instances)\n",
    "print (\"number of features:\", num_features)\n",
    "print (\"number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=0) # 70% training and 30% test\n",
    "print(\"Training set size:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing set size:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DT model \n",
    "DTmodel = DecisionTreeClassifier(criterion = 'gini', max_depth=10)\n",
    "\n",
    "# We fit the model with train data\n",
    "DTmodel.fit(x_train, y_train)\n",
    "\n",
    "# Make the predictions for test part\n",
    "y_pred = DTmodel.predict(x_test)\n",
    "\n",
    "# Compare prediction with actual y_test to get accuracy\n",
    "correct = y_test == y_pred\n",
    "incorrect = np.logical_not(correct)\n",
    "accuracy = np.sum(y_pred == y_test)/y_test.shape[0]\n",
    "print(f'accuracy is {accuracy*100:.1f}.')\n",
    "\n",
    "#Plot the results\n",
    "plt.scatter(x_train['sepal length'], x_train['sepal width'], c=y_train, marker='o', alpha=.2, label='train')\n",
    "plt.scatter(x_test['sepal length'].loc[correct], x_test['sepal width'].loc[correct], marker='.', c=y_pred[correct], label='correct')\n",
    "plt.scatter(x_test['sepal length'].loc[incorrect], x_test['sepal width'].loc[incorrect], marker='x', c=y_test[incorrect], label='misclassified')\n",
    "plt.ylabel('sepal length')\n",
    "plt.xlabel('sepal width')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "accuracy = np.sum(y_pred == y_test)/y_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot boundaries of the decision tree model\n",
    "x0v = np.linspace(np.min(x['sepal length']), np.max(x_train['sepal length']), 200)\n",
    "x1v = np.linspace(np.min(x['sepal width']), np.max(x_train['sepal width']), 200)\n",
    "x0,x1 = np.meshgrid(x0v, x1v)\n",
    "x_all = np.vstack((x0.ravel(),x1.ravel())).T\n",
    "y_train_prob = np.zeros((y_train.shape[0], num_classes))\n",
    "y_train_prob[np.arange(y_train.shape[0]), y_train] = 1\n",
    "y_prob_all = DTmodel.fit(x_train, y_train).predict(x_all)\n",
    "\n",
    "plt.scatter(x_train['sepal length'], x_train['sepal width'], c=y_train_prob, marker='o', alpha=1)\n",
    "plt.scatter(x_all[:,0], x_all[:,1], c=y_prob_all, marker='.', alpha=.01)\n",
    "plt.ylabel('sepal length')\n",
    "plt.xlabel('sepal width')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the tree\n",
    "plt.figure(figsize = (25,25))\n",
    "# Plot the decision tree, showing the decisive values and the improvements in Gini impurity along the way.\n",
    "plot_tree(DTmodel, filled=True, class_names=['setosa', 'versicolor', 'virginica'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DecisionTrees_Instructor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
